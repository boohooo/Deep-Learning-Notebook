{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Neural Machine Translation (NMT) w Attention",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "xCBI779dc_Il"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from string import digits\n",
        "import re\n",
        "import os\n",
        "import io\n",
        "import time"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QYz7Wdxjc_Kz"
      },
      "source": [
        "path_to_file = \"/content/drive/MyDrive/Colab Notebooks/kor.txt\""
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iAv2E8YEc_M6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "4d2ecd85-4be1-4f73-99eb-76453cd68ceb"
      },
      "source": [
        "lines = pd.read_table(path_to_file, names=['source', 'target', 'others'])\n",
        "lines = lines[['source', 'target']]\n",
        "lines.head()"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>source</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Go.</td>\n",
              "      <td>가.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Hi.</td>\n",
              "      <td>안녕.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Run!</td>\n",
              "      <td>뛰어!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Run.</td>\n",
              "      <td>뛰어.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Who?</td>\n",
              "      <td>누구?</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  source target\n",
              "0    Go.     가.\n",
              "1    Hi.    안녕.\n",
              "2   Run!    뛰어!\n",
              "3   Run.    뛰어.\n",
              "4   Who?    누구?"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_8WZairG6alv"
      },
      "source": [
        "np.savetxt('/content/drive/MyDrive/Colab Notebooks/kor2.txt', lines.values, fmt='%s', delimiter=\"\\t\")"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wDwYBuM2645n"
      },
      "source": [
        "path_to_nfile = \"/content/drive/MyDrive/Colab Notebooks/kor2.txt\""
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M9Ucnov_c_PG"
      },
      "source": [
        "# Text preprocessing\n",
        "def preprocess_sentence(x):\n",
        "\n",
        "\n",
        "  # Lowercase\n",
        "  x = x.lower()\n",
        "\n",
        "  x = re.sub(\" +\", \" \", x)\n",
        "  x = re.sub(\"'\", '', x)\n",
        "\n",
        "  # Add space between letter and punctuation\n",
        "  x = re.sub(r\"([?.!,¿])\", r\" \\1 \", x)\n",
        "  x = re.sub(r'[\" \"]+', \" \", x)\n",
        "\n",
        "  x = x.strip()\n",
        "\n",
        "  # Add start and end token to sentences\n",
        "  x = '<start> ' + x + ' <end>'\n",
        "  return x"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AjuW-gRd5R3m",
        "outputId": "f28b155c-66df-4220-9d29-98dcada7e212"
      },
      "source": [
        "en_sentence = u\"Do you like cooking?\"\n",
        "kr_sentence = u\"요리 좋아해?\"\n",
        "print(preprocess_sentence(en_sentence))\n",
        "print(preprocess_sentence(kr_sentence))"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<start> do you like cooking ? <end>\n",
            "<start> 요리 좋아해 ? <end>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oPjrBAyFc_RH"
      },
      "source": [
        "# Cleaning text \n",
        "# Add word pairs\n",
        "def create_dataset(path, num_examples):\n",
        "  \n",
        "  lines = io.open(path, encoding='UTF-8').read().strip().split('\\n')\n",
        "  \n",
        "  word_pairs = [[preprocess_sentence(w) for w in l.split('\\t')]  for l in lines[:num_examples]]\n",
        "  \n",
        "  return zip(*word_pairs)"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fO9-CdFbc_TS"
      },
      "source": [
        "# En-Kor word pairs | Source-Target\n",
        "sample_size = 50000\n",
        "en, kr = create_dataset(path_to_nfile, sample_size)"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X7OpMFJgc_a9"
      },
      "source": [
        "# Tokenizer for source (en)\n",
        "source_tokenizer = tf.keras.preprocessing.text.Tokenizer(filters='')\n",
        "source_tokenizer.fit_on_texts(en)\n",
        "# Sequencing\n",
        "source_tensor = source_tokenizer.texts_to_sequences(en)\n",
        "# Padding\n",
        "source_tensor = tf.keras.preprocessing.sequence.pad_sequences(source_tensor, padding='post')"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vlNdVPjUc_fZ"
      },
      "source": [
        "# Tokenizer for target (kr)\n",
        "target_tokenizer = tf.keras.preprocessing.text.Tokenizer(filters='')\n",
        "target_tokenizer.fit_on_texts(kr)\n",
        "# Sequencing\n",
        "target_tensor = target_tokenizer.texts_to_sequences(kr)\n",
        "# Padding\n",
        "target_tensor = tf.keras.preprocessing.sequence.pad_sequences(target_tensor, padding='post')"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k_RSaH8wc_Zo"
      },
      "source": [
        "# TTS\n",
        "source_train, source_test, target_train, target_test = train_test_split(source_tensor, target_tensor, test_size=0.2)"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QDaYxgFUc_Vg"
      },
      "source": [
        "# Some parameters\n",
        "BATCH_SIZE = 8\n",
        "BUFFER_SIZE = len(source_train)\n",
        "steps = len(source_train) // BATCH_SIZE\n",
        "embedding_dim = 256\n",
        "units = 1024\n",
        "\n",
        "# Vocab size\n",
        "source_vocab_size = len(source_tokenizer.word_index)+1\n",
        "target_vocab_size = len(target_tokenizer.word_index)+1\n",
        "\n",
        "# Create dataset\n",
        "dataset = tf.data.Dataset.from_tensor_slices((source_train, target_train)).shuffle(BATCH_SIZE)\n",
        "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
        "source_batch, target_batch = next(iter(dataset))\n"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "edlvD2uQLAQx"
      },
      "source": [
        "# Encoder\n",
        "class Encoder(tf.keras.Model):\n",
        "    def __init__(self, vocab_size, embedding_dim, encoder_units, batch_size):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.batch_size= batch_size\n",
        "        self.encoder_units=encoder_units\n",
        "        self.embedding=tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "        self.gru= tf.keras.layers.GRU(encoder_units, \n",
        "                                      return_sequences=True,\n",
        "                                      return_state=True,\n",
        "                                      recurrent_initializer='glorot_uniform')\n",
        "    \n",
        "    def call(self, x, hidden):\n",
        "        #pass the input x to the embedding layer\n",
        "        x= self.embedding(x)\n",
        "        # pass the embedding and the hidden state to GRU\n",
        "        output, state = self.gru(x, initial_state=hidden)\n",
        "        return output, state\n",
        "    \n",
        "    def initialize_hidden_state(self):\n",
        "        return tf.zeros((self.batch_size, self.encoder_units))"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qE4q6J0LLATN"
      },
      "source": [
        "encoder = Encoder(source_vocab_size, embedding_dim, units, BATCH_SIZE)\n"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EkUoaJ9fLAWF"
      },
      "source": [
        "# Bahdanau Attention Layer\n",
        "class BahdanauAttention(tf.keras.layers.Layer):\n",
        "  def __init__(self, units):\n",
        "    super(BahdanauAttention, self).__init__()\n",
        "    self.W1= tf.keras.layers.Dense(units)  # Encoder output\n",
        "    self.W2= tf.keras.layers.Dense(units)  # Decoder hidden\n",
        "    self.V= tf.keras.layers.Dense(1)\n",
        "  \n",
        "  def call(self, query, values):\n",
        "    #calculate the Attention score\n",
        "    hidden_with_time_axis = tf.expand_dims(query, 1)\n",
        "\n",
        "    score = self.V(tf.nn.tanh(self.W1(values) + self.W2(hidden_with_time_axis)))\n",
        "    \n",
        "    # attention_weights shape == (batch_size, max_length, 1)\n",
        "    attention_weights = tf.nn.softmax(score, axis=1)\n",
        "    \n",
        "      #context_vector \n",
        "    context_vector = attention_weights * values\n",
        "    \n",
        "    #Computes the sum of elements across dimensions of a tensor\n",
        "    context_vector = tf.reduce_sum(context_vector, axis=1)\n",
        "    return context_vector, attention_weights"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KogzVINKK-yK"
      },
      "source": [
        "# Decoder\n",
        "class Decoder(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, decoder_units, batch_size):\n",
        "    super(Decoder,self).__init__()\n",
        "    self.batch_size = batch_size\n",
        "    self.decoder_units = decoder_units\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "    self.gru = tf.keras.layers.GRU(decoder_units, \n",
        "                                   return_sequences= True, \n",
        "                                   return_state=True,\n",
        "                                   recurrent_initializer='glorot_uniform')\n",
        "    # Fully connected layer\n",
        "    self.fc= tf.keras.layers.Dense(vocab_size)\n",
        "    \n",
        "    # attention\n",
        "    self.attention = BahdanauAttention(self.decoder_units)\n",
        "    \n",
        "  def call(self, x, hidden, encoder_output):\n",
        "    context_vector, attention_weights = self.attention(hidden, encoder_output)\n",
        "    \n",
        "    # pass output sequnece thru the input layers\n",
        "    x = self.embedding(x)\n",
        "    \n",
        "    # concatenate context vector and embedding for output sequence\n",
        "    x = tf.concat([tf.expand_dims( context_vector, 1), x], axis=-1)\n",
        "    \n",
        "    # passing the concatenated vector to the GRU\n",
        "    output, state = self.gru(x)\n",
        "    \n",
        "    # output shape == (batch_size * 1, hidden_size)\n",
        "    output= tf.reshape(output, (-1, output.shape[2]))\n",
        "    \n",
        "    # pass the output thru Fc layers\n",
        "    x = self.fc(output)\n",
        "    return x, state, attention_weights"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LcHrP1eL9-Ru"
      },
      "source": [
        "decoder = Decoder(target_vocab_size, embedding_dim, units, BATCH_SIZE)"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hZrXuG8PK-4L"
      },
      "source": [
        "# Optimizer\n",
        "optimizer = tf.keras.optimizers.Adam()\n",
        "# Loss\n",
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')\n",
        "def loss_function(real, pred):                      \n",
        "  mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
        "  loss_ = loss_object(real, pred)\n",
        "\n",
        "  mask = tf.cast(mask, dtype=loss_.dtype)\n",
        "  loss_ *= mask\n",
        "\n",
        "  return tf.reduce_mean(loss_)"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5GJoFkSyK-7N"
      },
      "source": [
        "# Training\n",
        "def train_step(inp, targ, enc_hidden):\n",
        "  loss = 0\n",
        "\n",
        "  with tf.GradientTape() as tape:\n",
        "    enc_output, enc_hidden = encoder(inp, enc_hidden)\n",
        "\n",
        "    dec_hidden = enc_hidden\n",
        "\n",
        "    dec_input = tf.expand_dims([target_tokenizer.word_index['<start>']] * BATCH_SIZE, 1)\n",
        "\n",
        "    # Teacher forcing - feeding the target as the next input\n",
        "    for t in range(1, targ.shape[1]):\n",
        "      # passing enc_output to the decoder\n",
        "      predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output)\n",
        "\n",
        "      loss += loss_function(targ[:, t], predictions)\n",
        "\n",
        "      # using teacher forcing\n",
        "      dec_input = tf.expand_dims(targ[:, t], 1)\n",
        "\n",
        "  batch_loss = (loss / int(targ.shape[1]))\n",
        "\n",
        "  variables = encoder.trainable_variables + decoder.trainable_variables\n",
        "\n",
        "  gradients = tape.gradient(loss, variables)\n",
        "\n",
        "  optimizer.apply_gradients(zip(gradients, variables))\n",
        "\n",
        "  return batch_loss"
      ],
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RTHI1sK5K-3K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c977243c-d952-489d-b51d-c487a68055b9"
      },
      "source": [
        "EPOCHS = 1\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "  start = time.time()\n",
        "\n",
        "  enc_hidden = encoder.initialize_hidden_state()\n",
        "  total_loss = 0\n",
        "\n",
        "  for (batch, (inp, targ)) in enumerate(dataset.take(steps)):\n",
        "    batch_loss = train_step(inp, targ, enc_hidden)\n",
        "    total_loss += batch_loss\n",
        "    if batch % 100 == 0:\n",
        "      print('Epoch {} Batch {} loss {}'.format(epoch + 1,batch, batch_loss.numpy()))\n",
        "      \n",
        "  # saving (checkpoint) the model every 2 epochs\n",
        "  # if (epoch + 1) % 2 == 0:\n",
        "  #   checkpoint.save(file_prefix = checkpoint_prefix)\n",
        "\n",
        "  print('Epoch {} Loss {:.4f}'.format(epoch + 1, total_loss / steps))\n",
        "  print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 Batch 0 loss 0.4665137231349945\n",
            "Epoch 1 Batch 100 loss 0.3764806389808655\n",
            "Epoch 1 Batch 200 loss 0.36541956663131714\n",
            "Epoch 1 Batch 300 loss 0.35685038566589355\n",
            "Epoch 1 Loss 0.3799\n",
            "Time taken for 1 epoch 463.4818766117096 sec\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lfENIQo7K-1k"
      },
      "source": [
        "#Calculating the max length of the source and target sentences\n",
        "max_target_length= max(len(t) for t in target_tensor)\n",
        "max_source_length= max(len(t) for t in source_tensor)"
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NI69itnU5WM2"
      },
      "source": [
        "def evaluate(sentence):\n",
        "  attention_plot= np.zeros((max_target_length, max_source_length))\n",
        "  #preprocess the sentnece\n",
        "  sentence = preprocess_sentence(sentence)\n",
        "  \n",
        "  #convert the sentence to index based on word2index dictionary\n",
        "  inputs= [source_tokenizer.word_index[i] for i in sentence.split(' ')]\n",
        "  \n",
        "  # pad the sequence \n",
        "  inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs], maxlen=max_source_length, padding='post')\n",
        "  \n",
        "  #conver to tensors\n",
        "  inputs = tf.convert_to_tensor(inputs)\n",
        "  \n",
        "  result= ''\n",
        "  \n",
        "  # creating encoder\n",
        "  hidden = [tf.zeros((1, units))]\n",
        "  encoder_output, encoder_hidden= encoder(inputs, hidden)\n",
        "  \n",
        "  # creating decoder\n",
        "  decoder_hidden = encoder_hidden\n",
        "  decoder_input = tf.expand_dims([target_tokenizer.word_index['<start>']], 0)\n",
        "    \n",
        "  for t in range(max_target_length):\n",
        "\n",
        "    predictions, decoder_hidden, attention_weights= decoder(decoder_input, decoder_hidden, encoder_output)\n",
        "    \n",
        "    # storing attention weight for plotting it\n",
        "    attention_weights = tf.reshape(attention_weights, (-1,))\n",
        "    attention_plot[t] = attention_weights.numpy()\n",
        "    \n",
        "    prediction_id= tf.argmax(predictions[0]).numpy()\n",
        "    result += target_tokenizer.index_word[prediction_id] + ' '\n",
        "    \n",
        "    if target_tokenizer.index_word[prediction_id] == '<end>':\n",
        "      return result,sentence, attention_plot\n",
        "    \n",
        "    # predicted id is fed back to as input to the decoder\n",
        "    decoder_input = tf.expand_dims([prediction_id], 0)\n",
        "      \n",
        "  return result,sentence, attention_plot"
      ],
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cq7eEwdP5WQ5"
      },
      "source": [
        "def plot_attention(attention, sentence, predicted_sentence):\n",
        "  fig = plt.figure(figsize=(10,10))\n",
        "  ax= fig.add_subplot(1,1,1)\n",
        "  ax.matshow(attention, cmap='Greens')\n",
        "  fontdict={'fontsize':10}\n",
        "  \n",
        "  ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
        "  ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n",
        "  ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "  ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "  plt.show()"
      ],
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w8O0LoNL5WUr"
      },
      "source": [
        "def translate(sentence):\n",
        "  result, sentence, attention_plot = evaluate(sentence)\n",
        "  \n",
        "  print('Input : %s' % (sentence))\n",
        "  print('predicted sentence :{}'.format(result))\n",
        "  \n",
        "  attention_plot= attention_plot[:len(result.split(' ')), :len(sentence.split(' '))]\n",
        "  plot_attention(attention_plot, sentence.split(' '), result.split(' '))"
      ],
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 495
        },
        "id": "fOyFv_Yl5WTU",
        "outputId": "65b346c8-8bca-4f87-ca4f-f18af11f171d"
      },
      "source": [
        "translate(u'Oh no something is missing...')"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input : <start> oh no something is missing . . . <end>\n",
            "predicted sentence :난 . . <end> \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 45212 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 45212 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OV5URtlG5WPO"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}