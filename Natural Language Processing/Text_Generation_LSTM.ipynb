{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Text_Generation_LSTM.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "c3uRYJmAHYJr"
      },
      "source": [
        "import numpy \n",
        "import re\n",
        "import sys\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import LSTM\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.utils import np_utils"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AvOsPqHYHYMT"
      },
      "source": [
        "# Load text file\n",
        "path_to_file = 'trump.txt'\n",
        "text = open(path_to_file, 'rb').read().decode(encoding='utf-8')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0R0tAkalHYOf"
      },
      "source": [
        "# Clean the text\n",
        "# Function to clean the text\n",
        "def clean_text(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub('\\[.*?\\]', '', text)\n",
        "    text = re.sub('https?://\\S+|www\\.\\S+', '', text)\n",
        "    text = re.sub('<.*?>+', '', text)\n",
        "    text = re.sub('\\n', '', text)\n",
        "    text = re.sub('\\w*\\d\\w*', '', text)\n",
        "    text = \" \".join(filter(lambda x:x[0]!=\"@\", text.split()))\n",
        "    return text\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "crxguNDuog9d"
      },
      "source": [
        "# Apply the function\n",
        "text = clean_text(text)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c07i1bauHYQb"
      },
      "source": [
        "# Vectorize\n",
        "# Creating a mapping of unique char > integers\n",
        "chars = sorted(list(set(text)))\n",
        "char_to_int = dict((c, i) for i, c in enumerate(chars))"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RLE_zQyBoEIM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15e44c34-bf52-4cce-f11e-2a3fbad17981"
      },
      "source": [
        "# Check the number of unique chars\n",
        "n_chars = len(text)\n",
        "n_vocab = len(chars)\n",
        "print(\"Total Characters: \", n_chars)\n",
        "print(\"Total Vocab: \", n_vocab)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total Characters:  1745674\n",
            "Total Vocab:  163\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Pc4TsNfHYSt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "20b566e7-1c98-4fdb-a34b-d9ff449b073c"
      },
      "source": [
        "# Define the training data\n",
        "# Split the text into subsequences of 'seq_length'\n",
        "# 100 time steps of one char of x followed by y\n",
        "# A 'window' will slide across the text data one character at a time, allowing the character to be learned from the 100 characters preceding it\n",
        "# E.g. seq_length = 3\n",
        "# Oba > m\n",
        "# bam > a\n",
        "\n",
        "seq_length = 100\n",
        "\n",
        "tx = []\n",
        "ty = []\n",
        "\n",
        "# Input-Output pairs\n",
        "for i in range(0, n_chars - seq_length, 1):\n",
        "\tseq_in = text[i:i + seq_length]\n",
        "\tseq_out = text[i + seq_length]\n",
        "\ttx.append([char_to_int[char] for char in seq_in])\n",
        "\tty.append(char_to_int[seq_out])\n",
        "n_patterns = len(tx)\n",
        "\n",
        "# When we print we should have total number of char - seq_length\n",
        "print(\"Total Patterns: \", n_patterns)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total Patterns:  1745574\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-jrreMkDHYVL"
      },
      "source": [
        "# Reshape input sequences to [samples, time_steps, features]\n",
        "x = numpy.reshape(tx, (n_patterns, seq_length, 1))\n",
        "# Normalize to 0-1 (sigmoid)\n",
        "x = x/float(n_vocab)\n",
        "# One-hot encoding unique chars\n",
        "y = np_utils.to_categorical(ty)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1gzsUxMTHYXg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "40a743bf-a3a9-4c39-d040-727950d86cb7"
      },
      "source": [
        "# LSTM Model\n",
        "model = Sequential()\n",
        "model.add(LSTM(256, dropout=0.2, return_sequences=True, input_shape=(x.shape[1], x.shape[2])))\n",
        "model.add(LSTM(128, dropout=0.2))\n",
        "\n",
        "# Softmax for multi-class classification | Probability for ea char\n",
        "model.add(Dense(y.shape[1], activation='softmax'))\n",
        "\n",
        "model.summary()\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm (LSTM)                  (None, 100, 256)          264192    \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 128)               197120    \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 163)               21027     \n",
            "=================================================================\n",
            "Total params: 482,339\n",
            "Trainable params: 482,339\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ebQyogWGHYZs"
      },
      "source": [
        "# Checkpoints\n",
        "filepath=\"{epoch:02d}-{loss:.4f}.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
        "callbacks_list = [checkpoint]"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "62_br_ciHYb2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4bb1c48-922f-4ad6-9be2-8f924ccb3db6"
      },
      "source": [
        "# Fit model\n",
        "model.fit(x, y, epochs=2, batch_size=128, callbacks=callbacks_list)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "13637/13638 [============================>.] - ETA: 0s - loss: 3.0900\n",
            "Epoch 00001: loss improved from inf to 3.09004, saving model to 01-3.0900.hdf5\n",
            "13638/13638 [==============================] - 314s 23ms/step - loss: 3.0900\n",
            "Epoch 2/2\n",
            "13637/13638 [============================>.] - ETA: 0s - loss: 3.0149\n",
            "Epoch 00002: loss improved from 3.09004 to 3.01486, saving model to 02-3.0149.hdf5\n",
            "13638/13638 [==============================] - 321s 24ms/step - loss: 3.0149\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fbcbd7e7cc0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NvMxdO8uHYeA"
      },
      "source": [
        "# Our results are in integers, so, \n",
        "# Create a reverse mapping from integers > char\n",
        "int_to_char = dict((i, c) for i, c in enumerate(chars))"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hoQvU2HjHYgZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "daf35220-aeca-44cb-8629-5cf3048340a6"
      },
      "source": [
        "# Pick a random seed to start the sequence of predicted chars \n",
        "# Seed > generate1, generate1 > generate2, and so on..\n",
        "# E.g. i > c > e > c > r >..\n",
        "# Randomize seed\n",
        "start = numpy.random.randint(0, len(tx)-1)\n",
        "pattern = tx[start]\n",
        "result = []\n",
        "\n",
        "print(\"Seed: \", ''.join([int_to_char[value] for value in pattern]))"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Seed:  er and person, of real estate weekly, for the wonderful story on me. very much appreciated! “winning\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_KqJ4T2lws8c"
      },
      "source": [
        "def sample_prediction(prediction):\r\n",
        "  X = prediction[0]\r\n",
        "  rnd_idx = numpy.random.choice(len(X), p=X)\r\n",
        "  return rnd_idx"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QZd5xdleje49",
        "outputId": "84a30b24-882e-4b0b-d4ed-357853ade7d0"
      },
      "source": [
        "# Generate text of length _ \r\n",
        "for i in range(100):\r\n",
        "  x = numpy.reshape(pattern, (1, len(pattern), 1))\r\n",
        "  x = x / float(n_vocab)\r\n",
        "  prediction = model.predict(x, verbose=0)\r\n",
        "  index = sample_prediction(prediction)\r\n",
        "  #print(index)\r\n",
        "  result.append(int_to_char[index])\r\n",
        "  \r\n",
        "  pattern.append(index)\r\n",
        "  pattern = pattern[1:len(pattern)]\r\n",
        "\r\n",
        "print(result)\r\n",
        "print(\"Done\")"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['s', 't', 'e', 'e', 'n', 't', ':', ' ', 'b', ' ', 'c', 'o', 'v', ')', ' ', 'y', 'n', 'p', 'a', 't', 't', 'd', 'f', 'u', 'n', 'n', ' ', 'w', 'i', 'r', 'y', ' ', 'f', 'r', 'e', ' ', 'd', 'o', 'a', '.', 'd', 'm', 't', ' ', 'o', 'l', 'o', 'v', 'n', ' ', 'a', 'n', 'u', 's', 'a', ' ', 'h', 'v', ' ', 'f', 'r', ' ', 's', 'a', ' ', 'a', '@', '.', 'd', 'k', ' ', ' ', 'y', '.', '#', 'w', 'h', 'e', ' ', 'a', ' ', 'i', 'u', 'a', 'y', 'g', 'e', ' ', ' ', 'a', 'm', 'r', 'b', 'm', 'y', 'o', 'a', ' ', 'g', 'v', 'o', 'm', 'l', 's', 'e', ' ', 'y', 'a', 'f', ' ', 'a', ' ', 'b', 'e', 't', 's', 's', 't', ':', 'y', 'i', 'w', ',', ' ', 't', 'n', ' ', 'm', 'n', ' ', 'n', 'i', ' ', 't', 'n', 'l', 'u', 'e', 'e', ' ', 'e', 'r', 'i', 'n', 't', ' ', ' ', '.', 'y', 't', \"'\", 's', 'n', 'r', 'd', ' ', 'i', ' ', ' ', 'd', 'o', 'o', 'f', ' ', 'r', 's', 'g', '.', 'o', ' ', 'l', 't', ' ', 'c', 'y', 'g', ' ', 'n', 'n', ' ', 'c', ' ', 'u', 'n', 'g', 'c', ' ', 'n', 't', 's', ' ', 'a', 'n', 'm', ' ', 't', 'y', 'u', ' ', 'n']\n",
            "Done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GI8Hl2Ih6uZK"
      },
      "source": [
        "def toString(s):  \r\n",
        "    str1 = \"\"  \r\n",
        "    for ele in s:  \r\n",
        "        str1 += ele   \r\n",
        "    return str1  "
      ],
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AtXjW6Ckx44i",
        "outputId": "02cf33bf-2f79-49b9-d9ff-d72656b5a822",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "toString(result)"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"steent: b cov) ynpattdfunn wiry fre doa.dmt olovn anusa hv fr sa a@.dk  y.#whe a iuayge  amrbmyoa gvomlse yaf a betsst:yiw, tn mn ni tnluee erint  .yt'snrd i  doof rsg.o lt cyg nn c ungc nts anm tyu n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    }
  ]
}